{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Luftdaten data : data cleaning, resampling - mini version - cleaning v5\n",
    "\n",
    "# - TRYING TO HEAD FOR FINAL… \n",
    "## Code builds a continuous time tabular version of the luftdaen data, such that the same time period is present for each sensor in the data, regardless of whether each sensor has data for all the time slots. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reference documents\n",
    "\n",
    "Resampling time series data with Pandas ( Ben Alex Keen ) \n",
    "http://benalexkeen.com/resampling-time-series-data-with-pandas/\n",
    "\n",
    "Pandas reference manual : \n",
    "\n",
    ".at - access df values using nay kind of index, for SINGLE VALUES\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc\n",
    "\n",
    ".iat - only integer index values for getting/setting SINGLE df values\n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iat.html\n",
    "\n",
    ".loc - \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.loc.html#pandas.DataFrame.loc\n",
    "\n",
    ".iloc - purely integer indexed access ( getting/setting ) values \n",
    "https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.iloc.html#pandas.DataFrame.iloc\n",
    "\n",
    "datetime - documentation - useful for time! \n",
    "https://pandas.pydata.org/pandas-docs/stable/user_guide/timeseries.html\n",
    "\n",
    "rounding numbers in pyhton\n",
    "https://realpython.com/python-rounding/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### methods of filling … \n",
    "\n",
    "These are some of the common methods you might use for resampling:\n",
    "\n",
    "Method\tDescription\n",
    "\n",
    "bfill\tBackward fill\n",
    "\n",
    "count\tCount of values\n",
    "\n",
    "ffill\tForward fill\n",
    "\n",
    "first\tFirst valid data value\n",
    "\n",
    "last\tLast valid data value\n",
    "\n",
    "max\tMaximum data value\n",
    "\n",
    "mean\tMean of values in time range\n",
    "\n",
    "median\tMedian of values in time range\n",
    "\n",
    "min\tMinimum data value\n",
    "\n",
    "nunique\tNumber of unique values\n",
    "\n",
    "ohlc\tOpening value, highest value, lowest value, closing value\n",
    "\n",
    "pad\tSame as forward fill\n",
    "\n",
    "std\tStandard deviation of values\n",
    "\n",
    "sum\tSum of values\n",
    "\n",
    "var\tVariance of values\n",
    "\n",
    "#### time abbreviations \n",
    "\n",
    "Alias\tDescription\n",
    "\n",
    "B\tBusiness day\n",
    "\n",
    "D\tCalendar day\n",
    "\n",
    "W\tWeekly\n",
    "\n",
    "M\tMonth end\n",
    "\n",
    "Q\tQuarter end\n",
    "\n",
    "A\tYear end\n",
    "\n",
    "BA\tBusiness year end\n",
    "\n",
    "AS\tYear start\n",
    "\n",
    "H\tHourly frequency\n",
    "\n",
    "T, min\tMinutely frequency\n",
    "\n",
    "S\tSecondly frequency\n",
    "\n",
    "L, ms\tMillisecond frequency\n",
    "\n",
    "U, us\tMicrosecond frequency\n",
    "\n",
    "N, ns\tNanosecond frequency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "\n",
    "# start_time = \"2018-12-31 21:58:42\"\n",
    "end_time = \"2019-01-01 11:58:42\"\n",
    "# generate this please\n",
    "start_time = \"?????\"\n",
    "\n",
    "time_frequency_for_periods__for_basic_data = \"5T\"\n",
    "num_of_time_periods___for_basic_data = 24*20 # 24 hrs * 12 x 5 mins in each hour\n",
    "\n",
    "# when generating time periods \n",
    "sampling_frequency = \"3T\"\n",
    "\n",
    "\n",
    "\n",
    "# --- data urls \n",
    "\n",
    "curr_url = \"????\"\n",
    "nordic_midnight_24_hrs_data__url = \"/Users/miska/Documents/open_something/luftdaten/luftdaten_code/luftdaten__make_tabular_data__from_db_data/ld_NYE_midnight_24hrs_nordics_all_data_01.csv\"\n",
    "# nordic_midnight_24_hrs_data__url = \"/home/miska/documents/opensomething/luftdaten/dustmin_to_csv__various_code/ld_NYE_midnight_24hrs_nordics_all_data_01.csv\"\n",
    "\n",
    "\n",
    "\n",
    "# set the current data source \n",
    "curr_url = nordic_midnight_24_hrs_data__url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127109, 7)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# try convert the timestamp in the data, to epoch\n",
    "\n",
    "in_data = pd.read_csv( curr_url )\n",
    "in_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### basic variables ( set up )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " time_length_of_sample_period__in_seconds__as_pandas_resampleing_time : 180S\n"
     ]
    }
   ],
   "source": [
    "# time length of sample period\n",
    "time_length_of_sample_period__in_seconds = 60*3\n",
    "\n",
    "time_length_of_sample_period__in_seconds__as_pandas_resampleing_time = str(time_length_of_sample_period__in_seconds)+\"S\"\n",
    "print(\" time_length_of_sample_period__in_seconds__as_pandas_resampleing_time : \"+time_length_of_sample_period__in_seconds__as_pandas_resampleing_time )\n",
    "\n",
    "# how many time sample periods can fit in the current total data time period\n",
    "num_of_sample_time_periods_fit_in_total_sampled_period = 0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## general operations - what kind of time length in the data, are we outputting\n",
    "\n",
    "# for when we're creating 24 hour time segements\n",
    "default__generate_data_for_24_hour_period_starting_from_starttime = 'default__generate_data_for_24_hour_period_starting_from_starttime'\n",
    "\n",
    "# for when we're creating data files for the period until now\n",
    "default__generate_data_from_last_midnight_until_current_time =  \"default__generate_data_from_last_midnight_until_current_time\"\n",
    "\n",
    "# which are we using? \n",
    "current_time_duration_in_data_generation = default__generate_data_from_last_midnight_until_current_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure_out_how_many_sample_time_periods_fit_in_desired_sample_time_duration( which_time_duration_are_we_using, time_length_of_sample_period__in_seconds ):\n",
    "    \n",
    "    print(\">>> figure_out_how_many_sample_time_periods_fit_in_desired_sample_time_duration : checking time period : |\"+which_time_duration_are_we_using+\"| single sample time length : \"+str(time_length_of_sample_period__in_seconds) )\n",
    "    \n",
    "    num_of_sample_time_periods_fit_in_total_sampled_period = 0\n",
    "    \n",
    "    if which_time_duration_are_we_using == 'default__generate_data_for_24_hour_period_starting_from_starttime':\n",
    "        num_of_sample_time_periods_fit_in_total_sampled_period = int( ( 24*60*60 / time_length_of_sample_period__in_seconds ) ) \n",
    "    \n",
    "    if which_time_duration_are_we_using == 'default__generate_data_from_last_midnight_until_current_time':\n",
    "        ## - get time since midnight \n",
    "        \n",
    "        # generate timestamp, to get time since midnight \n",
    "        end_timestamp = pd.Timestamp.now()\n",
    "        hours_seconds_since_midnight = end_timestamp.hour*60*60\n",
    "        min_seconds_since_midnight = end_timestamp.minute*60\n",
    "        seconds_since_midnight = hours_seconds_since_midnight + min_seconds_since_midnight + end_timestamp.second\n",
    "        \n",
    "        print( \"\\n -- the number of seconds since midnight is \"+str( seconds_since_midnight ) )\n",
    "        \n",
    "        num_of_sample_time_periods_fit_in_total_sampled_period = int( seconds_since_midnight / time_length_of_sample_period__in_seconds ) \n",
    "        \n",
    "        \n",
    "    print(\"\\n - - - - FINALLY : num_of_sample_time_periods_fit_in_total_sampled_period : \"+str( num_of_sample_time_periods_fit_in_total_sampled_period ))\n",
    "    \n",
    "    return num_of_sample_time_periods_fit_in_total_sampled_period"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> figure_out_how_many_sample_time_periods_fit_in_desired_sample_time_duration : checking time period : |default__generate_data_for_24_hour_period_starting_from_starttime| single sample time length : 180\n",
      "\n",
      " - - - - FINALLY : num_of_sample_time_periods_fit_in_total_sampled_period : 480\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test fetching the number of sample periods in 24 hours \n",
    "figure_out_how_many_sample_time_periods_fit_in_desired_sample_time_duration( default__generate_data_for_24_hour_period_starting_from_starttime, time_length_of_sample_period__in_seconds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> figure_out_how_many_sample_time_periods_fit_in_desired_sample_time_duration : checking time period : |default__generate_data_from_last_midnight_until_current_time| single sample time length : 180\n",
      "\n",
      " -- the number of seconds since midnight is 35766\n",
      "\n",
      " - - - - FINALLY : num_of_sample_time_periods_fit_in_total_sampled_period : 198\n"
     ]
    }
   ],
   "source": [
    "# test fetching the number of sample periods since last midnight \n",
    "num_of_time_periods___for_basic_data = figure_out_how_many_sample_time_periods_fit_in_desired_sample_time_duration( default__generate_data_from_last_midnight_until_current_time, time_length_of_sample_period__in_seconds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "198"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_time_periods___for_basic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int( ( 12*60*60 + 47*60 ) / time_length_of_sample_period__in_seconds ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> figure_out_how_many_sample_time_periods_fit_in_desired_sample_time_duration : checking time period : |default__generate_data_for_24_hour_period_starting_from_starttime| single sample time length : 180\n",
      "\n",
      " - - - - FINALLY : num_of_sample_time_periods_fit_in_total_sampled_period : 480\n"
     ]
    }
   ],
   "source": [
    "num_of_time_periods___for_basic_data = figure_out_how_many_sample_time_periods_fit_in_desired_sample_time_duration( default__generate_data_for_24_hour_period_starting_from_starttime, time_length_of_sample_period__in_seconds )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "480"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_of_time_periods___for_basic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the list of unique sensor ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 205, numpy.ndarray)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_of_unique_sensor_ids = in_data['sensor_id'].unique()\n",
    "# num_of_unique_sensors = list_of_unique_sensor_ids.shape[0]\n",
    "list_of_unique_sensor_ids.shape[0], num_of_unique_sensors, type( list_of_unique_sensor_ids )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### make OUT DATA variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(98400,)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data__resampled_sensor_values_as_rows = np.array( np.zeros( list_of_unique_sensor_ids.shape[0] * num_of_time_periods___for_basic_data ) )\n",
    "out_data__resampled_sensor_values_as_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 480)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data__resampled_sensor_values_as_rows = out_data__resampled_sensor_values_as_rows.reshape( [ list_of_unique_sensor_ids.shape[0], num_of_time_periods___for_basic_data ] )\n",
    "out_data__resampled_sensor_values_as_rows.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((205, 480), (205, 480))"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_data__resampled_sensor_values_as_rows__p1_values = out_data__resampled_sensor_values_as_rows\n",
    "out_data__resampled_sensor_values_as_rows__p2_values = out_data__resampled_sensor_values_as_rows\n",
    "out_data__resampled_sensor_values_as_rows__p1_values.shape, out_data__resampled_sensor_values_as_rows__p2_values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "## TEMPORARY out data variable \n",
    "# ( until we run with live data, the size of the outputted data will be a bit wrong )\n",
    "\n",
    "temp_out_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(205, 2)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## make variable for LAT LONG coordinates of sensors\n",
    "# x2 so lat lon can be on one row \n",
    "sensors_lat_lon_list = np.array( np.zeros( list_of_unique_sensor_ids.shape[0] *2 ) )\n",
    "sensors_lat_lon_list = sensors_lat_lon_list.reshape( [ list_of_unique_sensor_ids.shape[0], 2 ] )\n",
    "sensors_lat_lon_list.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generate relevant timestamps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-02-20 00:00:00')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# timestamp last midnight \n",
    "end_timestamp = pd.Timestamp.now()\n",
    "timestamp_last_midnight = pd.Timestamp( end_timestamp.year, end_timestamp.month, end_timestamp.day, 0 )\n",
    "\n",
    "timestamp_last_midnight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timestamp('2019-02-20 09:58:49.986602')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timestamp_now = pd.Timestamp.now()\n",
    "timestamp_now"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sensor_id         int64\n",
       "sensor_namee     object\n",
       "lat             float64\n",
       "lon             float64\n",
       "timestamp        object\n",
       "p1              float64\n",
       "p2              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aha - timestamp column not a timestamp column?\n",
    "# - let's fix \n",
    "in_data['timestamp'] = pd.to_datetime( in_data['timestamp'] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas._libs.tslibs.timestamps.Timestamp"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the timestamps column type again\n",
    "type( in_data['timestamp'][0] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the timestamp column as the index \n",
    "in_data = in_data.set_index( 'timestamp' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-12-31 11:57:22', '2018-12-31 11:58:44',\n",
       "               '2018-12-31 11:58:47', '2018-12-31 11:56:41',\n",
       "               '2018-12-31 11:57:42', '2018-12-31 11:57:52',\n",
       "               '2018-12-31 11:58:51', '2018-12-31 11:58:28',\n",
       "               '2018-12-31 11:57:18', '2018-12-31 11:57:22',\n",
       "               ...\n",
       "               '2019-01-01 11:59:41', '2019-01-01 11:59:46',\n",
       "               '2019-01-01 11:57:19', '2019-01-01 11:59:59',\n",
       "               '2019-01-01 11:56:55', '2019-01-01 11:58:57',\n",
       "               '2019-01-01 11:59:36', '2019-01-01 11:59:41',\n",
       "               '2019-01-01 11:57:12', '2019-01-01 11:58:42'],\n",
       "              dtype='datetime64[ns]', name='timestamp', length=127109, freq=None)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_data = in_data.sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatetimeIndex(['2018-12-31 11:55:19', '2018-12-31 11:56:37',\n",
       "               '2018-12-31 11:56:38', '2018-12-31 11:56:39',\n",
       "               '2018-12-31 11:56:40', '2018-12-31 11:56:40',\n",
       "               '2018-12-31 11:56:40', '2018-12-31 11:56:41',\n",
       "               '2018-12-31 11:56:42', '2018-12-31 11:56:43',\n",
       "               ...\n",
       "               '2019-01-01 23:59:54', '2019-01-01 23:59:54',\n",
       "               '2019-01-01 23:59:55', '2019-01-01 23:59:55',\n",
       "               '2019-01-01 23:59:56', '2019-01-01 23:59:56',\n",
       "               '2019-01-01 23:59:56', '2019-01-01 23:59:56',\n",
       "               '2019-01-01 23:59:57', '2019-01-01 23:59:58'],\n",
       "              dtype='datetime64[ns]', name='timestamp', length=127109, freq=None)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check\n",
    "in_data.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### set up blank start and end rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p1  p2\n",
       "2019-02-20 NaN NaN"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data__START_TIME__blank_row = pd.DataFrame( data={\"p1\": np.NaN, \"p2\" : np.NaN }, index=pd.DatetimeIndex( [timestamp_last_midnight] ) )\n",
    "in_data__START_TIME__blank_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p1</th>\n",
       "      <th>p2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2019-02-20</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            p1  p2\n",
       "2019-02-20 NaN NaN"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "in_data__END_TIME__blank_row = pd.DataFrame( data={\"p1\": np.NaN, \"p2\" : np.NaN }, index=pd.DatetimeIndex( [end_timestamp] ) )\n",
    "in_data__START_TIME__blank_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loop and resample! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for timing \n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- - the first row looks like this sensor_id         7273\n",
      "sensor_namee    SDS011\n",
      "lat             60.002\n",
      "lon             17.846\n",
      "p1                3.43\n",
      "p2                1.56\n",
      "Name: 2018-12-31 11:57:22, dtype: object\n",
      "- - - - lat lon output test : \n",
      "60.001999999999995, 17.846\n",
      "\n",
      "\n",
      "- - working on sensor id 7273 - - got 716 rows of data\n",
      "- - - got columns : Index(['p1', 'p2'], dtype='object')\n",
      "- - - current data length = (717, 2)\n",
      "- - - current data length = (718, 2)\n",
      "                       p1    p2\n",
      "2019-02-20 00:00:00   NaN   NaN\n",
      "2018-12-31 11:57:22  3.43  1.56\n",
      "2018-12-31 11:59:50  3.78  1.55\n",
      "2018-12-31 12:04:47  4.12  1.90\n",
      "2018-12-31 12:07:16  3.45  1.75\n",
      "2018-12-31 12:09:44  2.10  1.36\n",
      "2018-12-31 12:12:13  1.45  1.16\n",
      "2018-12-31 12:14:43  2.02  1.28\n",
      "2018-12-31 12:19:43  1.78  1.36\n",
      "2018-12-31 12:22:12  2.00  1.36\n",
      "                              p1    p2\n",
      "2019-01-01 23:33:59.000000  3.68  1.18\n",
      "2019-01-01 23:36:27.000000  3.73  1.08\n",
      "2019-01-01 23:38:56.000000  4.75  1.25\n",
      "2019-01-01 23:41:33.000000  3.35  1.15\n",
      "2019-01-01 23:46:33.000000  2.88  1.10\n",
      "2019-01-01 23:46:33.000000  2.88  1.10\n",
      "2019-01-01 23:51:36.000000  3.49  1.12\n",
      "2019-01-01 23:54:04.000000  2.90  1.22\n",
      "2019-01-01 23:56:33.000000  4.14  1.48\n",
      "2019-02-20 09:58:49.818947   NaN   NaN\n",
      "\n",
      "- - - printing resampled data ( shape : (24441, 2)) \n",
      "                        p1     p2\n",
      "2018-12-31 11:57:00  3.605  1.555\n",
      "2018-12-31 12:00:00    NaN    NaN\n",
      "2018-12-31 12:03:00  4.120  1.900\n",
      "2018-12-31 12:06:00  3.450  1.750\n",
      "2018-12-31 12:09:00  2.100  1.360\n",
      "2018-12-31 12:12:00  1.735  1.220\n",
      "2018-12-31 12:15:00    NaN    NaN\n",
      "2018-12-31 12:18:00  1.780  1.360\n",
      "2018-12-31 12:21:00  2.000  1.360\n",
      "2018-12-31 12:24:00  2.450  1.420\n",
      "                     p1  p2\n",
      "2019-02-20 09:30:00 NaN NaN\n",
      "2019-02-20 09:33:00 NaN NaN\n",
      "2019-02-20 09:36:00 NaN NaN\n",
      "2019-02-20 09:39:00 NaN NaN\n",
      "2019-02-20 09:42:00 NaN NaN\n",
      "2019-02-20 09:45:00 NaN NaN\n",
      "2019-02-20 09:48:00 NaN NaN\n",
      "2019-02-20 09:51:00 NaN NaN\n",
      "2019-02-20 09:54:00 NaN NaN\n",
      "2019-02-20 09:57:00 NaN NaN\n",
      "- - the first row looks like this sensor_id         7275\n",
      "sensor_namee    SDS011\n",
      "lat              57.72\n",
      "lon             11.888\n",
      "p1              482.77\n",
      "p2               33.82\n",
      "Name: 2018-12-31 11:58:44, dtype: object\n",
      "- - - - lat lon output test : \n",
      "57.72, 11.888\n",
      "\n",
      "\n",
      "- - working on sensor id 7275 - - got 692 rows of data\n",
      "- - - got columns : Index(['p1', 'p2'], dtype='object')\n",
      "- - - current data length = (693, 2)\n",
      "- - - current data length = (694, 2)\n",
      "                         p1     p2\n",
      "2019-02-20 00:00:00     NaN    NaN\n",
      "2018-12-31 11:58:44  482.77  33.82\n",
      "2018-12-31 12:01:12  455.92  31.15\n",
      "2018-12-31 12:03:39  521.07  36.56\n",
      "2018-12-31 12:06:07  440.70  36.53\n",
      "2018-12-31 12:06:07  496.38  37.33\n",
      "2018-12-31 12:13:48  496.34  32.25\n",
      "2018-12-31 12:16:16  486.08  31.22\n",
      "2018-12-31 12:18:43  454.58  31.52\n",
      "2018-12-31 12:21:11  476.68  32.57\n",
      "                              p1    p2\n",
      "2019-01-01 23:32:10.000000  3.03  0.80\n",
      "2019-01-01 23:35:21.000000  2.27  0.77\n",
      "2019-01-01 23:38:22.000000  6.00  1.20\n",
      "2019-01-01 23:41:26.000000  3.03  0.97\n",
      "2019-01-01 23:44:33.000000  2.00  1.40\n",
      "2019-01-01 23:47:42.000000  2.38  1.15\n",
      "2019-01-01 23:54:18.000000  3.23  0.93\n",
      "2019-01-01 23:57:06.000000  2.96  1.02\n",
      "2019-01-01 23:57:06.000000  2.70  1.10\n",
      "2019-02-20 09:58:49.818947   NaN   NaN\n",
      "\n",
      "- - - printing resampled data ( shape : (24441, 2)) \n",
      "                         p1      p2\n",
      "2018-12-31 11:57:00  482.77  33.820\n",
      "2018-12-31 12:00:00  455.92  31.150\n",
      "2018-12-31 12:03:00  521.07  36.560\n",
      "2018-12-31 12:06:00  468.54  36.930\n",
      "2018-12-31 12:09:00     NaN     NaN\n",
      "2018-12-31 12:12:00  496.34  32.250\n",
      "2018-12-31 12:15:00  486.08  31.220\n",
      "2018-12-31 12:18:00  454.58  31.520\n",
      "2018-12-31 12:21:00  443.18  31.125\n",
      "2018-12-31 12:24:00  345.40  26.160\n",
      "                     p1  p2\n",
      "2019-02-20 09:30:00 NaN NaN\n",
      "2019-02-20 09:33:00 NaN NaN\n",
      "2019-02-20 09:36:00 NaN NaN\n",
      "2019-02-20 09:39:00 NaN NaN\n",
      "2019-02-20 09:42:00 NaN NaN\n",
      "2019-02-20 09:45:00 NaN NaN\n",
      "2019-02-20 09:48:00 NaN NaN\n",
      "2019-02-20 09:51:00 NaN NaN\n",
      "2019-02-20 09:54:00 NaN NaN\n",
      "2019-02-20 09:57:00 NaN NaN\n"
     ]
    }
   ],
   "source": [
    "# loop\n",
    "for current_sensor_id_i in range( len( list_of_unique_sensor_ids[:2] )):\n",
    "\n",
    "    # get current sensor id \n",
    "    current_sensor_id = list_of_unique_sensor_ids[ current_sensor_id_i ]\n",
    "    \n",
    "    # get all the values of the current sensor id \n",
    "    curr_sensor_id__in_data = in_data[ in_data['sensor_id'] == current_sensor_id ]\n",
    "    \n",
    "    print(\"- - the first row looks like this \"+str( curr_sensor_id__in_data.iloc[0] ) )\n",
    "    \n",
    "    # save lat/lon data\n",
    "    sensors_lat_lon_list[ current_sensor_id_i, 0 ] = curr_sensor_id__in_data.iloc[0]['lat'] \n",
    "    sensors_lat_lon_list[ current_sensor_id_i, 1 ] = curr_sensor_id__in_data.iloc[0]['lon'] \n",
    "    # test output \n",
    "    print(\"- - - - lat lon output test : \")\n",
    "    print( str( sensors_lat_lon_list[ current_sensor_id_i, 0 ] )+\", \"+str( sensors_lat_lon_list[ current_sensor_id_i, 1 ] ) )\n",
    "    print(  )\n",
    "\n",
    "    \n",
    "#     print(\"- - - current sensor lat/on : \"+str( sensors_lat_lon_list[ current_sensor_id_i, 0 ] )+\",\"+str( sensors_lat_lon_list[ current_sensor_id_i, 1 ] ) )\n",
    "#     print(\"- - - - input lat lon : \"+str( curr_sensor_id__in_data[0]['lat'] )+\",\"+str( curr_sensor_id__in_data[0]['lon'] ) )    \n",
    "    \n",
    "    \n",
    "    # minimise the in_data, so it's easier to resample the p1 and p2 values\n",
    "    curr_sensor_id__in_data = curr_sensor_id__in_data[ ['p1', 'p2'] ]\n",
    "    \n",
    "    print(\"\\n- - working on sensor id \"+str( current_sensor_id)+\" - - got \"+str( curr_sensor_id__in_data.shape[0])+\" rows of data\" )\n",
    "    \n",
    "    print( \"- - - got columns : \"+str( curr_sensor_id__in_data.columns ) ) \n",
    "    \n",
    "    ## INSERT bland start and end points \n",
    "    \n",
    "    curr_sensor_id__in_data__with_blank_start_time = in_data__START_TIME__blank_row.append( curr_sensor_id__in_data )\n",
    "    \n",
    "    print(\"- - - current data length = \"+str( curr_sensor_id__in_data__with_blank_start_time.shape ))\n",
    "    \n",
    "    curr_sensor_id__in_data__with_blank_start_AND_end_time = curr_sensor_id__in_data__with_blank_start_time.append( in_data__END_TIME__blank_row )\n",
    "    \n",
    "    print(\"- - - current data length = \"+str( curr_sensor_id__in_data__with_blank_start_AND_end_time.shape ))   \n",
    "    \n",
    "    print( curr_sensor_id__in_data__with_blank_start_AND_end_time[:10] )\n",
    "    print( curr_sensor_id__in_data__with_blank_start_AND_end_time[-10:] )    \n",
    "    \n",
    "    curr_sensor_id__in_data__with_blank_start_AND_end_time__RESAMPLED = curr_sensor_id__in_data__with_blank_start_AND_end_time.resample( time_length_of_sample_period__in_seconds__as_pandas_resampleing_time ).mean()\n",
    "    \n",
    "    print(\"\\n- - - printing resampled data ( shape : \"+str( curr_sensor_id__in_data__with_blank_start_AND_end_time__RESAMPLED.shape)+\") \")\n",
    "    \n",
    "    print( curr_sensor_id__in_data__with_blank_start_AND_end_time__RESAMPLED[:10] )\n",
    "    print( curr_sensor_id__in_data__with_blank_start_AND_end_time__RESAMPLED[-10:] )\n",
    "    \n",
    "    ## SAVE DATA\n",
    "    \n",
    "    temp_out_data.append( curr_sensor_id__in_data__with_blank_start_AND_end_time__RESAMPLED )\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[                        p1     p2\n",
       " 2018-12-31 11:57:00  3.605  1.555\n",
       " 2018-12-31 12:00:00    NaN    NaN\n",
       " 2018-12-31 12:03:00  4.120  1.900\n",
       " 2018-12-31 12:06:00  3.450  1.750\n",
       " 2018-12-31 12:09:00  2.100  1.360\n",
       " 2018-12-31 12:12:00  1.735  1.220\n",
       " 2018-12-31 12:15:00    NaN    NaN\n",
       " 2018-12-31 12:18:00  1.780  1.360\n",
       " 2018-12-31 12:21:00  2.000  1.360\n",
       " 2018-12-31 12:24:00  2.450  1.420\n",
       " 2018-12-31 12:27:00  3.125  1.675\n",
       " 2018-12-31 12:30:00    NaN    NaN\n",
       " 2018-12-31 12:33:00  2.300  1.880\n",
       " 2018-12-31 12:36:00  2.800  1.840\n",
       " 2018-12-31 12:39:00  2.740  1.750\n",
       " 2018-12-31 12:42:00  3.000  1.800\n",
       " 2018-12-31 12:45:00  2.950  1.830\n",
       " 2018-12-31 12:48:00  2.460  1.750\n",
       " 2018-12-31 12:51:00  3.200  1.600\n",
       " 2018-12-31 12:54:00  2.710  1.480\n",
       " 2018-12-31 12:57:00    NaN    NaN\n",
       " 2018-12-31 13:00:00  2.350  1.420\n",
       " 2018-12-31 13:03:00  2.250  1.280\n",
       " 2018-12-31 13:06:00  2.500  1.360\n",
       " 2018-12-31 13:09:00  2.075  1.425\n",
       " 2018-12-31 13:12:00    NaN    NaN\n",
       " 2018-12-31 13:15:00  2.250  1.620\n",
       " 2018-12-31 13:18:00  2.220  1.640\n",
       " 2018-12-31 13:21:00  2.160  1.550\n",
       " 2018-12-31 13:24:00  3.675  1.955\n",
       " ...                    ...    ...\n",
       " 2019-02-20 08:30:00    NaN    NaN\n",
       " 2019-02-20 08:33:00    NaN    NaN\n",
       " 2019-02-20 08:36:00    NaN    NaN\n",
       " 2019-02-20 08:39:00    NaN    NaN\n",
       " 2019-02-20 08:42:00    NaN    NaN\n",
       " 2019-02-20 08:45:00    NaN    NaN\n",
       " 2019-02-20 08:48:00    NaN    NaN\n",
       " 2019-02-20 08:51:00    NaN    NaN\n",
       " 2019-02-20 08:54:00    NaN    NaN\n",
       " 2019-02-20 08:57:00    NaN    NaN\n",
       " 2019-02-20 09:00:00    NaN    NaN\n",
       " 2019-02-20 09:03:00    NaN    NaN\n",
       " 2019-02-20 09:06:00    NaN    NaN\n",
       " 2019-02-20 09:09:00    NaN    NaN\n",
       " 2019-02-20 09:12:00    NaN    NaN\n",
       " 2019-02-20 09:15:00    NaN    NaN\n",
       " 2019-02-20 09:18:00    NaN    NaN\n",
       " 2019-02-20 09:21:00    NaN    NaN\n",
       " 2019-02-20 09:24:00    NaN    NaN\n",
       " 2019-02-20 09:27:00    NaN    NaN\n",
       " 2019-02-20 09:30:00    NaN    NaN\n",
       " 2019-02-20 09:33:00    NaN    NaN\n",
       " 2019-02-20 09:36:00    NaN    NaN\n",
       " 2019-02-20 09:39:00    NaN    NaN\n",
       " 2019-02-20 09:42:00    NaN    NaN\n",
       " 2019-02-20 09:45:00    NaN    NaN\n",
       " 2019-02-20 09:48:00    NaN    NaN\n",
       " 2019-02-20 09:51:00    NaN    NaN\n",
       " 2019-02-20 09:54:00    NaN    NaN\n",
       " 2019-02-20 09:57:00    NaN    NaN\n",
       " \n",
       " [24441 rows x 2 columns],                           p1      p2\n",
       " 2018-12-31 11:57:00  482.770  33.820\n",
       " 2018-12-31 12:00:00  455.920  31.150\n",
       " 2018-12-31 12:03:00  521.070  36.560\n",
       " 2018-12-31 12:06:00  468.540  36.930\n",
       " 2018-12-31 12:09:00      NaN     NaN\n",
       " 2018-12-31 12:12:00  496.340  32.250\n",
       " 2018-12-31 12:15:00  486.080  31.220\n",
       " 2018-12-31 12:18:00  454.580  31.520\n",
       " 2018-12-31 12:21:00  443.180  31.125\n",
       " 2018-12-31 12:24:00  345.400  26.160\n",
       " 2018-12-31 12:27:00  357.930  23.950\n",
       " 2018-12-31 12:30:00  288.470  20.380\n",
       " 2018-12-31 12:33:00  301.720  20.075\n",
       " 2018-12-31 12:36:00      NaN     NaN\n",
       " 2018-12-31 12:39:00  284.030  19.420\n",
       " 2018-12-31 12:42:00  232.870  16.500\n",
       " 2018-12-31 12:45:00  226.200  14.580\n",
       " 2018-12-31 12:48:00  250.415  17.195\n",
       " 2018-12-31 12:51:00      NaN     NaN\n",
       " 2018-12-31 12:54:00  293.520  22.420\n",
       " 2018-12-31 12:57:00  262.680  22.060\n",
       " 2018-12-31 13:00:00  205.500  17.110\n",
       " 2018-12-31 13:03:00      NaN     NaN\n",
       " 2018-12-31 13:06:00  178.520  16.510\n",
       " 2018-12-31 13:09:00   73.340  10.120\n",
       " 2018-12-31 13:12:00   46.040   8.750\n",
       " 2018-12-31 13:15:00   25.995   8.290\n",
       " 2018-12-31 13:18:00      NaN     NaN\n",
       " 2018-12-31 13:21:00   26.180   9.840\n",
       " 2018-12-31 13:24:00   21.850   9.570\n",
       " ...                      ...     ...\n",
       " 2019-02-20 08:30:00      NaN     NaN\n",
       " 2019-02-20 08:33:00      NaN     NaN\n",
       " 2019-02-20 08:36:00      NaN     NaN\n",
       " 2019-02-20 08:39:00      NaN     NaN\n",
       " 2019-02-20 08:42:00      NaN     NaN\n",
       " 2019-02-20 08:45:00      NaN     NaN\n",
       " 2019-02-20 08:48:00      NaN     NaN\n",
       " 2019-02-20 08:51:00      NaN     NaN\n",
       " 2019-02-20 08:54:00      NaN     NaN\n",
       " 2019-02-20 08:57:00      NaN     NaN\n",
       " 2019-02-20 09:00:00      NaN     NaN\n",
       " 2019-02-20 09:03:00      NaN     NaN\n",
       " 2019-02-20 09:06:00      NaN     NaN\n",
       " 2019-02-20 09:09:00      NaN     NaN\n",
       " 2019-02-20 09:12:00      NaN     NaN\n",
       " 2019-02-20 09:15:00      NaN     NaN\n",
       " 2019-02-20 09:18:00      NaN     NaN\n",
       " 2019-02-20 09:21:00      NaN     NaN\n",
       " 2019-02-20 09:24:00      NaN     NaN\n",
       " 2019-02-20 09:27:00      NaN     NaN\n",
       " 2019-02-20 09:30:00      NaN     NaN\n",
       " 2019-02-20 09:33:00      NaN     NaN\n",
       " 2019-02-20 09:36:00      NaN     NaN\n",
       " 2019-02-20 09:39:00      NaN     NaN\n",
       " 2019-02-20 09:42:00      NaN     NaN\n",
       " 2019-02-20 09:45:00      NaN     NaN\n",
       " 2019-02-20 09:48:00      NaN     NaN\n",
       " 2019-02-20 09:51:00      NaN     NaN\n",
       " 2019-02-20 09:54:00      NaN     NaN\n",
       " 2019-02-20 09:57:00      NaN     NaN\n",
       " \n",
       " [24441 rows x 2 columns]]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_out_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[60.002, 17.846],\n",
       "       [57.72 , 11.888],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ],\n",
       "       [ 0.   ,  0.   ]])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check lat long list \n",
    "sensors_lat_lon_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[60.001999999999995, 17.846],\n",
       " [57.72, 11.888],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0],\n",
       " [0.0, 0.0]]"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert lat lon array to a regular list, for expor \n",
    "sensors_lat_lon_list = sensors_lat_lon_list.tolist()\n",
    "sensors_lat_lon_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## how to export data? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "json : \n",
    "- data_time_period_start\n",
    "- data_time_period_end\n",
    "- sample_length\n",
    "- num_of_sample_periods\n",
    "- list_of_sensor_ids\n",
    "- lat_lon # in the same order as sensor_ids\n",
    "- p1_values # in the same order as sensor_ids\n",
    "- p2_values # in the same order as sensor_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "exported_data = {}\n",
    "exported_data[ 'data_time_period_start' ] = \"starttime_variable\"\n",
    "exported_data[ 'data_time_period_end' ] = \"endtime_variable\"\n",
    "exported_data[ 'individual_data_sample_length_in_seconds' ] = time_length_of_sample_period__in_seconds\n",
    "exported_data[ 'num_of_sample_periods' ] = num_of_time_periods___for_basic_data\n",
    "exported_data[ 'sensor_ids' ] = list_of_unique_sensor_ids\n",
    "exported_data[ 'lat_lon' ] = sensors_lat_lon_list\n",
    "exported_data[ 'data__p1_values' ] = out_data__resampled_sensor_values_as_rows__p1_values\n",
    "exported_data[ 'data__p1_values' ] = out_data__resampled_sensor_values_as_rows__p2_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GOOD THINGS to have and remember"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "np.round # rounds entire arrays to given accuracy "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TO DO NEXT "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fix that things run from a server \n",
    "( - eg fetch the data from the server ) \n",
    "- fix that the p1/p2 values get saves to a np array, rather than the current list\n",
    "\n",
    "- test with different time periods\n",
    "\n",
    "- run as a cron job… "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
